{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1708283007433,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "36wZV4G372WT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "#from google.colab import drive\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1368,
     "status": "ok",
     "timestamp": 1708283010081,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "UBPzbcsME_ei",
    "outputId": "0b4a8033-12df-413e-a85a-00961d3810c7"
   },
   "outputs": [],
   "source": [
    "with open('iris.csv', 'r') as f:\n",
    "  temp = np.genfromtxt(f, dtype='f4', delimiter=',')\n",
    "for i in range(temp.shape[0]):\n",
    "    if temp[i][-1] == 1.0:\n",
    "        temp[i][-1] = 0.0\n",
    "    else:\n",
    "        temp[i][-1] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1708283014184,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "41FxqWjuDVcm"
   },
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # The examples are read at random, in no particular order\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = tf.constant(indices[i:min(i + batch_size, num_examples)])\n",
    "        yield tf.gather(features, j), tf.gather(labels, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1708283024844,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "XSCNT519s7xF"
   },
   "outputs": [],
   "source": [
    "# Optimization algorithm Stochastic Gradient Descent\n",
    "def sgd(param, grad, lr, batch_size):\n",
    "  param.assign_sub(lr * grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1708283027585,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "oplV28fQ0ZTy"
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def cross_entropy(z, t):\n",
    "  return tf.keras.losses.CategoricalCrossentropy()(t,z)\n",
    "  #return  -(1/len(z))*tf.reduce_sum(tf.math.log(z)*t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1708283030082,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "WVKNCTXuBB9A"
   },
   "outputs": [],
   "source": [
    "def model(x,w):\n",
    "  # layer with softmax function\n",
    "  u = np.hstack((np.ones((x.shape[0],1)), x))@w\n",
    "  u_exp = tf.math.exp(u)\n",
    "  z = u_exp/tf.reduce_sum(u_exp,axis=1,keepdims=True)\n",
    "  # if softmax activation is to be used,\n",
    "  # z = tf.nn.softmax(u)\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1708286689017,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "ViCDki3gFPVg",
    "outputId": "c4d04b43-ef9a-4bc4-bf5b-446007a91cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "# Data Prep\n",
    "\n",
    "X = temp[:,0:-1]\n",
    "# One-hot output layer encoding (label 1 = class 1, label 0 = not class 1\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "LB = LabelBinarizer()\n",
    "labels = LB.fit_transform(temp[:,-1])\n",
    "labels = np.hstack((labels, 1 - labels))\n",
    "print(labels.shape)\n",
    "\n",
    "# K: Nsamples, d: featureDimension, N: Nclasses\n",
    "K,d = X.shape\n",
    "N = labels.shape[1]\n",
    "\n",
    "# partition into 80/20% training/testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, train_size=0.8, shuffle=True, random_state=3, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1708272602082,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "g0jpjWjTGP51"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 10\n",
    "lr = 0.03 # learning rate\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2913,
     "status": "ok",
     "timestamp": 1708272604984,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "VYKa1O-iFDrK",
    "outputId": "6f4d4aa6-32b5-48b4-ab7e-d784a423b164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.058622\n",
      "epoch 2, loss 0.054919\n",
      "epoch 3, loss 0.051538\n",
      "epoch 4, loss 0.048665\n",
      "epoch 5, loss 0.046013\n",
      "epoch 6, loss 0.043711\n",
      "epoch 7, loss 0.041699\n",
      "epoch 8, loss 0.039713\n",
      "epoch 9, loss 0.038012\n",
      "epoch 10, loss 0.036433\n",
      "epoch 11, loss 0.034989\n",
      "epoch 12, loss 0.033642\n",
      "epoch 13, loss 0.032404\n",
      "epoch 14, loss 0.031259\n",
      "epoch 15, loss 0.030200\n",
      "epoch 16, loss 0.029227\n",
      "epoch 17, loss 0.028276\n",
      "epoch 18, loss 0.027413\n",
      "epoch 19, loss 0.026605\n",
      "epoch 20, loss 0.025854\n",
      "epoch 21, loss 0.025118\n",
      "epoch 22, loss 0.024471\n",
      "epoch 23, loss 0.023798\n",
      "epoch 24, loss 0.023190\n",
      "epoch 25, loss 0.022611\n",
      "epoch 26, loss 0.022062\n",
      "epoch 27, loss 0.021544\n",
      "epoch 28, loss 0.021044\n",
      "epoch 29, loss 0.020571\n",
      "epoch 30, loss 0.020118\n",
      "epoch 31, loss 0.019686\n",
      "epoch 32, loss 0.019278\n",
      "epoch 33, loss 0.018885\n",
      "epoch 34, loss 0.018502\n",
      "epoch 35, loss 0.018138\n",
      "epoch 36, loss 0.017787\n",
      "epoch 37, loss 0.017452\n",
      "epoch 38, loss 0.017130\n",
      "epoch 39, loss 0.016820\n",
      "epoch 40, loss 0.016522\n",
      "epoch 41, loss 0.016233\n",
      "epoch 42, loss 0.015956\n",
      "epoch 43, loss 0.015687\n",
      "epoch 44, loss 0.015428\n",
      "epoch 45, loss 0.015178\n",
      "epoch 46, loss 0.014936\n",
      "epoch 47, loss 0.014702\n",
      "epoch 48, loss 0.014475\n",
      "epoch 49, loss 0.014256\n",
      "epoch 50, loss 0.014043\n"
     ]
    }
   ],
   "source": [
    "# Learning\n",
    "\n",
    "w = tf.Variable(tf.random.normal(shape=(d+1,N)), trainable=True)\n",
    "for epoch in range(num_epochs):\n",
    "  for x, y in data_iter(batch_size, X_train, y_train):\n",
    "    # Feed-forward model\n",
    "    with tf.GradientTape() as g:\n",
    "      l = cross_entropy(model(x, w),y)\n",
    "    # Compute gradient on l with respect to w\n",
    "    dw = g.gradient(l, w)\n",
    "    # Update parameters using their gradient\n",
    "    sgd(w, dw, lr, batch_size)\n",
    "  # After one epoch, Evaluate resubstitution loss\n",
    "  train_loss = cross_entropy(model(tf.constant(X_train), w),y_train)\n",
    "  print(f'epoch {epoch + 1}, loss {float(tf.reduce_mean(train_loss)):f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1708287710188,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "THNnf8ERXqE7",
    "outputId": "385ab1ed-9218-43bb-9d36-ebef562647ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix= \n",
      " [[20.  0.]\n",
      " [ 0. 10.]]\n",
      "Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Performance Evaluation\n",
    "# Z_test is the linear model output (real #)\n",
    "Z_test = model(X_test,w)\n",
    "# idx is an array consisting of the index of largest output of each sample\n",
    "idx = np.argmax(Z_test,axis=1)\n",
    "# y_pred is one hot encoding of the predicted output\n",
    "y_pred = np.zeros((idx.size, N))\n",
    "y_pred[np.arange(idx.size),idx] = 1\n",
    "# Cmat is the confusion matrix\n",
    "Cmat = y_test.T@y_pred\n",
    "Accuracy = np.round(100*np.sum(np.diagonal(Cmat))/np.sum(Cmat),2)\n",
    "print('Confusion Matrix= \\n', Cmat)\n",
    "print('Accuracy = ', Accuracy, '%' )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
