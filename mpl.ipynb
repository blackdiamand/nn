{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "with open('winequality-white.csv', 'r') as f:\n",
    "  temp = np.genfromtxt(f,delimiter=',', skip_header=1)\n",
    "  X = temp[:,:-1]\n",
    "  y = temp[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7c0ed126cbebf1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T02:56:54.091535Z",
     "start_time": "2024-03-18T02:56:52.707233Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 1)\n",
      "(4898, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y = y.reshape((-1,1))\n",
    "print(y.shape)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y)\n",
    "#print(enc.transform(y).toarray())\n",
    "y_enc = enc.transform(y).toarray()\n",
    "print(y_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bd26e3be536bc21",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.721e-01 -8.327e-02  2.133e-01 ... -1.247e+00 -3.492e-01 -1.393e+00]\n",
      " [-6.575e-01  2.141e-01  4.800e-02 ...  7.400e-01  1.342e-03 -8.243e-01]\n",
      " [ 1.476e+00  1.584e-02  5.438e-01 ...  4.751e-01 -4.368e-01 -3.367e-01]\n",
      " ...\n",
      " [-4.205e-01 -3.806e-01 -1.192e+00 ... -1.313e+00 -2.616e-01 -9.055e-01]\n",
      " [-1.606e+00  1.150e-01 -2.826e-01 ...  1.005e+00 -9.626e-01  1.858e+00]\n",
      " [-1.013e+00 -6.779e-01  3.786e-01 ...  4.751e-01 -1.488e+00  1.045e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_scaled = scaler.transform(X)\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e6d7d12-7697-4ded-82db-e6893895e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_presplit, X_test, y_presplit, y_test = train_test_split(X_scaled,y_enc,test_size=0.2,train_size=0.8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_presplit,y_presplit,test_size=0.25,train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "443ef1d1-1923-41db-bd1c-a24c46997111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 11)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(11, input_dim=11, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68d24616-4611-4f5f-b98d-4be39d1b4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e08538f-dbca-427b-b765-04f72ae78057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.5450 - accuracy: 0.2379 - val_loss: 0.3669 - val_accuracy: 0.4214\n",
      "Epoch 2/100\n",
      "184/184 [==============================] - 0s 710us/step - loss: 0.3238 - accuracy: 0.4506 - val_loss: 0.3130 - val_accuracy: 0.4510\n",
      "Epoch 3/100\n",
      "184/184 [==============================] - 0s 680us/step - loss: 0.3053 - accuracy: 0.4530 - val_loss: 0.3033 - val_accuracy: 0.4510\n",
      "Epoch 4/100\n",
      "184/184 [==============================] - 0s 686us/step - loss: 0.2972 - accuracy: 0.4564 - val_loss: 0.2966 - val_accuracy: 0.4490\n",
      "Epoch 5/100\n",
      "184/184 [==============================] - 0s 684us/step - loss: 0.2909 - accuracy: 0.4629 - val_loss: 0.2923 - val_accuracy: 0.4551\n",
      "Epoch 6/100\n",
      "184/184 [==============================] - 0s 705us/step - loss: 0.2864 - accuracy: 0.4717 - val_loss: 0.2874 - val_accuracy: 0.4571\n",
      "Epoch 7/100\n",
      "184/184 [==============================] - 0s 702us/step - loss: 0.2822 - accuracy: 0.4779 - val_loss: 0.2833 - val_accuracy: 0.4704\n",
      "Epoch 8/100\n",
      "184/184 [==============================] - 0s 686us/step - loss: 0.2789 - accuracy: 0.4874 - val_loss: 0.2804 - val_accuracy: 0.4694\n",
      "Epoch 9/100\n",
      "184/184 [==============================] - 0s 696us/step - loss: 0.2757 - accuracy: 0.5044 - val_loss: 0.2774 - val_accuracy: 0.5061\n",
      "Epoch 10/100\n",
      "184/184 [==============================] - 0s 739us/step - loss: 0.2730 - accuracy: 0.5218 - val_loss: 0.2754 - val_accuracy: 0.5357\n",
      "Epoch 11/100\n",
      "184/184 [==============================] - 0s 689us/step - loss: 0.2712 - accuracy: 0.5327 - val_loss: 0.2736 - val_accuracy: 0.5265\n",
      "Epoch 12/100\n",
      "184/184 [==============================] - 0s 708us/step - loss: 0.2699 - accuracy: 0.5334 - val_loss: 0.2726 - val_accuracy: 0.5306\n",
      "Epoch 13/100\n",
      "184/184 [==============================] - 0s 713us/step - loss: 0.2681 - accuracy: 0.5354 - val_loss: 0.2718 - val_accuracy: 0.5347\n",
      "Epoch 14/100\n",
      "184/184 [==============================] - 0s 760us/step - loss: 0.2668 - accuracy: 0.5391 - val_loss: 0.2708 - val_accuracy: 0.5347\n",
      "Epoch 15/100\n",
      "184/184 [==============================] - 0s 732us/step - loss: 0.2657 - accuracy: 0.5371 - val_loss: 0.2701 - val_accuracy: 0.5306\n",
      "Epoch 16/100\n",
      "184/184 [==============================] - 0s 709us/step - loss: 0.2645 - accuracy: 0.5419 - val_loss: 0.2694 - val_accuracy: 0.5276\n",
      "Epoch 17/100\n",
      "184/184 [==============================] - 0s 708us/step - loss: 0.2636 - accuracy: 0.5391 - val_loss: 0.2686 - val_accuracy: 0.5347\n",
      "Epoch 18/100\n",
      "184/184 [==============================] - 0s 701us/step - loss: 0.2629 - accuracy: 0.5425 - val_loss: 0.2683 - val_accuracy: 0.5255\n",
      "Epoch 19/100\n",
      "184/184 [==============================] - 0s 743us/step - loss: 0.2624 - accuracy: 0.5412 - val_loss: 0.2678 - val_accuracy: 0.5286\n",
      "Epoch 20/100\n",
      "184/184 [==============================] - 0s 689us/step - loss: 0.2618 - accuracy: 0.5388 - val_loss: 0.2668 - val_accuracy: 0.5286\n",
      "Epoch 21/100\n",
      "184/184 [==============================] - 0s 723us/step - loss: 0.2613 - accuracy: 0.5429 - val_loss: 0.2662 - val_accuracy: 0.5378\n",
      "Epoch 22/100\n",
      "184/184 [==============================] - 0s 699us/step - loss: 0.2606 - accuracy: 0.5442 - val_loss: 0.2660 - val_accuracy: 0.5316\n",
      "Epoch 23/100\n",
      "184/184 [==============================] - 0s 695us/step - loss: 0.2599 - accuracy: 0.5487 - val_loss: 0.2654 - val_accuracy: 0.5388\n",
      "Epoch 24/100\n",
      "184/184 [==============================] - 0s 704us/step - loss: 0.2594 - accuracy: 0.5470 - val_loss: 0.2649 - val_accuracy: 0.5378\n",
      "Epoch 25/100\n",
      "184/184 [==============================] - 0s 706us/step - loss: 0.2591 - accuracy: 0.5538 - val_loss: 0.2648 - val_accuracy: 0.5367\n",
      "Epoch 26/100\n",
      "184/184 [==============================] - 0s 696us/step - loss: 0.2584 - accuracy: 0.5480 - val_loss: 0.2648 - val_accuracy: 0.5388\n",
      "Epoch 27/100\n",
      "184/184 [==============================] - 0s 692us/step - loss: 0.2577 - accuracy: 0.5507 - val_loss: 0.2648 - val_accuracy: 0.5357\n",
      "Epoch 28/100\n",
      "184/184 [==============================] - 0s 685us/step - loss: 0.2575 - accuracy: 0.5487 - val_loss: 0.2643 - val_accuracy: 0.5418\n",
      "Epoch 29/100\n",
      "184/184 [==============================] - 0s 682us/step - loss: 0.2570 - accuracy: 0.5517 - val_loss: 0.2645 - val_accuracy: 0.5357\n",
      "Epoch 30/100\n",
      "184/184 [==============================] - 0s 692us/step - loss: 0.2567 - accuracy: 0.5507 - val_loss: 0.2637 - val_accuracy: 0.5429\n",
      "Epoch 31/100\n",
      "184/184 [==============================] - 0s 675us/step - loss: 0.2562 - accuracy: 0.5517 - val_loss: 0.2640 - val_accuracy: 0.5357\n",
      "Epoch 32/100\n",
      "184/184 [==============================] - 0s 680us/step - loss: 0.2561 - accuracy: 0.5517 - val_loss: 0.2637 - val_accuracy: 0.5449\n",
      "Epoch 33/100\n",
      "184/184 [==============================] - 0s 689us/step - loss: 0.2558 - accuracy: 0.5517 - val_loss: 0.2637 - val_accuracy: 0.5347\n",
      "Epoch 34/100\n",
      "184/184 [==============================] - 0s 688us/step - loss: 0.2556 - accuracy: 0.5562 - val_loss: 0.2630 - val_accuracy: 0.5357\n",
      "Epoch 35/100\n",
      "184/184 [==============================] - 0s 708us/step - loss: 0.2551 - accuracy: 0.5558 - val_loss: 0.2629 - val_accuracy: 0.5408\n",
      "Epoch 36/100\n",
      "184/184 [==============================] - 0s 718us/step - loss: 0.2554 - accuracy: 0.5585 - val_loss: 0.2633 - val_accuracy: 0.5408\n",
      "Epoch 37/100\n",
      "184/184 [==============================] - 0s 709us/step - loss: 0.2547 - accuracy: 0.5538 - val_loss: 0.2624 - val_accuracy: 0.5367\n",
      "Epoch 38/100\n",
      "184/184 [==============================] - 0s 850us/step - loss: 0.2544 - accuracy: 0.5582 - val_loss: 0.2624 - val_accuracy: 0.5398\n",
      "Epoch 39/100\n",
      "184/184 [==============================] - 0s 747us/step - loss: 0.2542 - accuracy: 0.5558 - val_loss: 0.2619 - val_accuracy: 0.5439\n",
      "Epoch 40/100\n",
      "184/184 [==============================] - 0s 917us/step - loss: 0.2540 - accuracy: 0.5558 - val_loss: 0.2622 - val_accuracy: 0.5459\n",
      "Epoch 41/100\n",
      "184/184 [==============================] - 0s 750us/step - loss: 0.2538 - accuracy: 0.5579 - val_loss: 0.2617 - val_accuracy: 0.5408\n",
      "Epoch 42/100\n",
      "184/184 [==============================] - 0s 680us/step - loss: 0.2536 - accuracy: 0.5609 - val_loss: 0.2613 - val_accuracy: 0.5429\n",
      "Epoch 43/100\n",
      "184/184 [==============================] - 0s 709us/step - loss: 0.2534 - accuracy: 0.5596 - val_loss: 0.2612 - val_accuracy: 0.5429\n",
      "Epoch 44/100\n",
      "184/184 [==============================] - 0s 715us/step - loss: 0.2530 - accuracy: 0.5633 - val_loss: 0.2624 - val_accuracy: 0.5398\n",
      "Epoch 45/100\n",
      "184/184 [==============================] - 0s 770us/step - loss: 0.2532 - accuracy: 0.5592 - val_loss: 0.2614 - val_accuracy: 0.5490\n",
      "Epoch 46/100\n",
      "184/184 [==============================] - 0s 802us/step - loss: 0.2529 - accuracy: 0.5582 - val_loss: 0.2616 - val_accuracy: 0.5408\n",
      "Epoch 47/100\n",
      "184/184 [==============================] - 0s 678us/step - loss: 0.2527 - accuracy: 0.5565 - val_loss: 0.2610 - val_accuracy: 0.5429\n",
      "Epoch 48/100\n",
      "184/184 [==============================] - 0s 670us/step - loss: 0.2526 - accuracy: 0.5585 - val_loss: 0.2608 - val_accuracy: 0.5439\n",
      "Epoch 49/100\n",
      "184/184 [==============================] - 0s 677us/step - loss: 0.2528 - accuracy: 0.5548 - val_loss: 0.2605 - val_accuracy: 0.5459\n",
      "Epoch 50/100\n",
      "184/184 [==============================] - 0s 670us/step - loss: 0.2523 - accuracy: 0.5626 - val_loss: 0.2607 - val_accuracy: 0.5388\n",
      "Epoch 51/100\n",
      "184/184 [==============================] - 0s 699us/step - loss: 0.2521 - accuracy: 0.5616 - val_loss: 0.2613 - val_accuracy: 0.5367\n",
      "Epoch 52/100\n",
      "184/184 [==============================] - 0s 696us/step - loss: 0.2521 - accuracy: 0.5606 - val_loss: 0.2605 - val_accuracy: 0.5439\n",
      "Epoch 53/100\n",
      "184/184 [==============================] - 0s 708us/step - loss: 0.2518 - accuracy: 0.5609 - val_loss: 0.2610 - val_accuracy: 0.5398\n",
      "Epoch 54/100\n",
      "184/184 [==============================] - 0s 670us/step - loss: 0.2521 - accuracy: 0.5616 - val_loss: 0.2602 - val_accuracy: 0.5439\n",
      "Epoch 55/100\n",
      "184/184 [==============================] - 0s 661us/step - loss: 0.2515 - accuracy: 0.5633 - val_loss: 0.2604 - val_accuracy: 0.5408\n",
      "Epoch 56/100\n",
      "184/184 [==============================] - 0s 701us/step - loss: 0.2513 - accuracy: 0.5660 - val_loss: 0.2601 - val_accuracy: 0.5510\n",
      "Epoch 57/100\n",
      "184/184 [==============================] - 0s 695us/step - loss: 0.2513 - accuracy: 0.5667 - val_loss: 0.2600 - val_accuracy: 0.5439\n",
      "Epoch 58/100\n",
      "184/184 [==============================] - 0s 797us/step - loss: 0.2511 - accuracy: 0.5596 - val_loss: 0.2601 - val_accuracy: 0.5459\n",
      "Epoch 59/100\n",
      "184/184 [==============================] - 0s 707us/step - loss: 0.2511 - accuracy: 0.5630 - val_loss: 0.2600 - val_accuracy: 0.5480\n",
      "Epoch 60/100\n",
      "184/184 [==============================] - 0s 660us/step - loss: 0.2515 - accuracy: 0.5633 - val_loss: 0.2599 - val_accuracy: 0.5469\n",
      "Epoch 61/100\n",
      "184/184 [==============================] - 0s 667us/step - loss: 0.2508 - accuracy: 0.5636 - val_loss: 0.2596 - val_accuracy: 0.5541\n",
      "Epoch 62/100\n",
      "184/184 [==============================] - 0s 673us/step - loss: 0.2506 - accuracy: 0.5640 - val_loss: 0.2597 - val_accuracy: 0.5418\n",
      "Epoch 63/100\n",
      "184/184 [==============================] - 0s 708us/step - loss: 0.2505 - accuracy: 0.5667 - val_loss: 0.2595 - val_accuracy: 0.5480\n",
      "Epoch 64/100\n",
      "184/184 [==============================] - 0s 669us/step - loss: 0.2502 - accuracy: 0.5671 - val_loss: 0.2599 - val_accuracy: 0.5500\n",
      "Epoch 65/100\n",
      "184/184 [==============================] - 0s 653us/step - loss: 0.2502 - accuracy: 0.5650 - val_loss: 0.2599 - val_accuracy: 0.5510\n",
      "Epoch 66/100\n",
      "184/184 [==============================] - 0s 675us/step - loss: 0.2501 - accuracy: 0.5660 - val_loss: 0.2595 - val_accuracy: 0.5500\n",
      "Epoch 67/100\n",
      "184/184 [==============================] - 0s 682us/step - loss: 0.2500 - accuracy: 0.5688 - val_loss: 0.2595 - val_accuracy: 0.5459\n",
      "Epoch 68/100\n",
      "184/184 [==============================] - 0s 693us/step - loss: 0.2498 - accuracy: 0.5660 - val_loss: 0.2600 - val_accuracy: 0.5429\n",
      "Epoch 69/100\n",
      "184/184 [==============================] - 0s 688us/step - loss: 0.2497 - accuracy: 0.5636 - val_loss: 0.2593 - val_accuracy: 0.5480\n",
      "Epoch 70/100\n",
      "184/184 [==============================] - 0s 658us/step - loss: 0.2497 - accuracy: 0.5671 - val_loss: 0.2600 - val_accuracy: 0.5439\n",
      "Epoch 71/100\n",
      "184/184 [==============================] - 0s 662us/step - loss: 0.2492 - accuracy: 0.5684 - val_loss: 0.2594 - val_accuracy: 0.5520\n",
      "Epoch 72/100\n",
      "184/184 [==============================] - 0s 659us/step - loss: 0.2492 - accuracy: 0.5677 - val_loss: 0.2596 - val_accuracy: 0.5449\n",
      "Epoch 73/100\n",
      "184/184 [==============================] - 0s 657us/step - loss: 0.2489 - accuracy: 0.5650 - val_loss: 0.2597 - val_accuracy: 0.5459\n",
      "Epoch 74/100\n",
      "184/184 [==============================] - 0s 662us/step - loss: 0.2489 - accuracy: 0.5640 - val_loss: 0.2597 - val_accuracy: 0.5459\n",
      "Epoch 75/100\n",
      "184/184 [==============================] - 0s 673us/step - loss: 0.2489 - accuracy: 0.5667 - val_loss: 0.2603 - val_accuracy: 0.5551\n",
      "Epoch 76/100\n",
      "184/184 [==============================] - 0s 664us/step - loss: 0.2488 - accuracy: 0.5694 - val_loss: 0.2594 - val_accuracy: 0.5531\n",
      "Epoch 77/100\n",
      "184/184 [==============================] - 0s 676us/step - loss: 0.2490 - accuracy: 0.5654 - val_loss: 0.2594 - val_accuracy: 0.5480\n",
      "Epoch 78/100\n",
      "184/184 [==============================] - 0s 663us/step - loss: 0.2486 - accuracy: 0.5684 - val_loss: 0.2594 - val_accuracy: 0.5449\n",
      "Epoch 79/100\n",
      "184/184 [==============================] - 0s 687us/step - loss: 0.2486 - accuracy: 0.5684 - val_loss: 0.2592 - val_accuracy: 0.5469\n",
      "Epoch 80/100\n",
      "184/184 [==============================] - 0s 744us/step - loss: 0.2482 - accuracy: 0.5674 - val_loss: 0.2593 - val_accuracy: 0.5480\n",
      "Epoch 81/100\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5664 - val_loss: 0.2593 - val_accuracy: 0.5490\n",
      "Epoch 82/100\n",
      "184/184 [==============================] - 0s 726us/step - loss: 0.2480 - accuracy: 0.5708 - val_loss: 0.2595 - val_accuracy: 0.5480\n",
      "Epoch 83/100\n",
      "184/184 [==============================] - 0s 718us/step - loss: 0.2481 - accuracy: 0.5681 - val_loss: 0.2595 - val_accuracy: 0.5500\n",
      "Epoch 84/100\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.5671 - val_loss: 0.2590 - val_accuracy: 0.5449\n",
      "Epoch 85/100\n",
      "184/184 [==============================] - 0s 758us/step - loss: 0.2477 - accuracy: 0.5694 - val_loss: 0.2597 - val_accuracy: 0.5490\n",
      "Epoch 86/100\n",
      "184/184 [==============================] - 0s 791us/step - loss: 0.2478 - accuracy: 0.5735 - val_loss: 0.2591 - val_accuracy: 0.5480\n",
      "Epoch 87/100\n",
      "184/184 [==============================] - 0s 743us/step - loss: 0.2476 - accuracy: 0.5701 - val_loss: 0.2587 - val_accuracy: 0.5418\n",
      "Epoch 88/100\n",
      "184/184 [==============================] - 0s 697us/step - loss: 0.2473 - accuracy: 0.5664 - val_loss: 0.2589 - val_accuracy: 0.5480\n",
      "Epoch 89/100\n",
      "184/184 [==============================] - 0s 730us/step - loss: 0.2473 - accuracy: 0.5694 - val_loss: 0.2596 - val_accuracy: 0.5459\n",
      "Epoch 90/100\n",
      "184/184 [==============================] - 0s 679us/step - loss: 0.2474 - accuracy: 0.5664 - val_loss: 0.2601 - val_accuracy: 0.5490\n",
      "Epoch 91/100\n",
      "184/184 [==============================] - 0s 658us/step - loss: 0.2473 - accuracy: 0.5681 - val_loss: 0.2590 - val_accuracy: 0.5500\n",
      "Epoch 92/100\n",
      "184/184 [==============================] - 0s 666us/step - loss: 0.2473 - accuracy: 0.5691 - val_loss: 0.2593 - val_accuracy: 0.5531\n",
      "Epoch 93/100\n",
      "184/184 [==============================] - 0s 663us/step - loss: 0.2472 - accuracy: 0.5725 - val_loss: 0.2589 - val_accuracy: 0.5449\n",
      "Epoch 94/100\n",
      "184/184 [==============================] - 0s 665us/step - loss: 0.2470 - accuracy: 0.5698 - val_loss: 0.2589 - val_accuracy: 0.5531\n",
      "Epoch 95/100\n",
      "184/184 [==============================] - 0s 669us/step - loss: 0.2473 - accuracy: 0.5711 - val_loss: 0.2591 - val_accuracy: 0.5459\n",
      "Epoch 96/100\n",
      "184/184 [==============================] - 0s 726us/step - loss: 0.2471 - accuracy: 0.5667 - val_loss: 0.2591 - val_accuracy: 0.5469\n",
      "Epoch 97/100\n",
      "184/184 [==============================] - 0s 831us/step - loss: 0.2467 - accuracy: 0.5688 - val_loss: 0.2601 - val_accuracy: 0.5531\n",
      "Epoch 98/100\n",
      "184/184 [==============================] - 0s 708us/step - loss: 0.2470 - accuracy: 0.5701 - val_loss: 0.2587 - val_accuracy: 0.5449\n",
      "Epoch 99/100\n",
      "184/184 [==============================] - 0s 663us/step - loss: 0.2466 - accuracy: 0.5636 - val_loss: 0.2587 - val_accuracy: 0.5500\n",
      "Epoch 100/100\n",
      "184/184 [==============================] - 0s 665us/step - loss: 0.2469 - accuracy: 0.5742 - val_loss: 0.2591 - val_accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a3969af0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "net.fit(X_train, y_train, epochs=100, batch_size = 16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23053341-8bfb-471f-adfe-bb5c77bcbd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 551us/step - loss: 0.2509 - accuracy: 0.5684\n",
      "Test results - Loss: 0.25092700123786926 - Accuracy: 0.5683673620223999%\n",
      "31/31 [==============================] - 0s 367us/step\n",
      "(980,)\n",
      "(980, 7)\n",
      "[[3. 4. 3. ... 3. 3. 3.]\n",
      " [3. 3. 3. ... 4. 3. 3.]\n",
      " [3. 3. 3. ... 3. 3. 3.]\n",
      " ...\n",
      " [3. 3. 4. ... 3. 3. 3.]\n",
      " [3. 3. 3. ... 3. 3. 3.]\n",
      " [3. 3. 3. ... 3. 3. 3.]]\n",
      "tf.Tensor(\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  0   0   1   7   4   0   0]\n",
      " [  1  10  75 133  46  12   1]\n",
      " [  1  16 172 244 108  27   0]\n",
      " [  1   5  40  58  14   2   2]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0]], shape=(7, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = net.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred = np.argmax(net.predict(X_test), axis=-1)\n",
    "print(y_pred.shape)\n",
    "print(y_val.shape)\n",
    "print(y_val)\n",
    "\n",
    "b = (np.argmax(y_val, axis = 1) + 3)\n",
    "\n",
    "print(tf.math.confusion_matrix(y_pred, b)[:-3,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb3cc67b-f5cf-4db8-9fcd-2ea80e76784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "184/184 [==============================] - 1s 1ms/step - loss: 0.5224 - accuracy: 0.2236 - val_loss: 8.0688 - val_accuracy: 0.4510\n",
      "Epoch 2/100\n",
      "184/184 [==============================] - 0s 794us/step - loss: 0.3145 - accuracy: 0.4530 - val_loss: 8.9583 - val_accuracy: 0.4510\n",
      "Epoch 3/100\n",
      "184/184 [==============================] - 0s 747us/step - loss: 0.3045 - accuracy: 0.4530 - val_loss: 8.6703 - val_accuracy: 0.4510\n",
      "Epoch 4/100\n",
      "184/184 [==============================] - 0s 696us/step - loss: 0.3017 - accuracy: 0.4530 - val_loss: 9.3043 - val_accuracy: 0.4510\n",
      "Epoch 5/100\n",
      "184/184 [==============================] - 0s 682us/step - loss: 0.2998 - accuracy: 0.4530 - val_loss: 9.5670 - val_accuracy: 0.4510\n",
      "Epoch 6/100\n",
      "184/184 [==============================] - 0s 719us/step - loss: 0.2957 - accuracy: 0.4554 - val_loss: 10.4080 - val_accuracy: 0.4622\n",
      "Epoch 7/100\n",
      "184/184 [==============================] - 0s 767us/step - loss: 0.2893 - accuracy: 0.4711 - val_loss: 10.5177 - val_accuracy: 0.4673\n",
      "Epoch 8/100\n",
      "184/184 [==============================] - 0s 676us/step - loss: 0.2847 - accuracy: 0.4796 - val_loss: 10.3037 - val_accuracy: 0.4949\n",
      "Epoch 9/100\n",
      "184/184 [==============================] - 0s 704us/step - loss: 0.2808 - accuracy: 0.4816 - val_loss: 10.7014 - val_accuracy: 0.4806\n",
      "Epoch 10/100\n",
      "184/184 [==============================] - 0s 702us/step - loss: 0.2777 - accuracy: 0.4888 - val_loss: 10.7757 - val_accuracy: 0.5051\n",
      "Epoch 11/100\n",
      "184/184 [==============================] - 0s 689us/step - loss: 0.2759 - accuracy: 0.4925 - val_loss: 10.8085 - val_accuracy: 0.5173\n",
      "Epoch 12/100\n",
      "184/184 [==============================] - 0s 732us/step - loss: 0.2737 - accuracy: 0.5000 - val_loss: 10.5001 - val_accuracy: 0.5143\n",
      "Epoch 13/100\n",
      "184/184 [==============================] - 0s 695us/step - loss: 0.2724 - accuracy: 0.5065 - val_loss: 11.5176 - val_accuracy: 0.5224\n",
      "Epoch 14/100\n",
      "184/184 [==============================] - 0s 685us/step - loss: 0.2713 - accuracy: 0.5075 - val_loss: 11.3951 - val_accuracy: 0.5235\n",
      "Epoch 15/100\n",
      "184/184 [==============================] - 0s 695us/step - loss: 0.2699 - accuracy: 0.5163 - val_loss: 11.0191 - val_accuracy: 0.5184\n",
      "Epoch 16/100\n",
      "184/184 [==============================] - 0s 720us/step - loss: 0.2694 - accuracy: 0.5119 - val_loss: 10.6919 - val_accuracy: 0.5235\n",
      "Epoch 17/100\n",
      "184/184 [==============================] - 0s 727us/step - loss: 0.2688 - accuracy: 0.5187 - val_loss: 10.7821 - val_accuracy: 0.5245\n",
      "Epoch 18/100\n",
      "184/184 [==============================] - 0s 701us/step - loss: 0.2679 - accuracy: 0.5201 - val_loss: 11.1793 - val_accuracy: 0.5255\n",
      "Epoch 19/100\n",
      "184/184 [==============================] - 0s 745us/step - loss: 0.2675 - accuracy: 0.5238 - val_loss: 10.9263 - val_accuracy: 0.5286\n",
      "Epoch 20/100\n",
      "184/184 [==============================] - 0s 714us/step - loss: 0.2665 - accuracy: 0.5211 - val_loss: 10.9463 - val_accuracy: 0.5235\n",
      "Epoch 21/100\n",
      "184/184 [==============================] - 0s 665us/step - loss: 0.2664 - accuracy: 0.5238 - val_loss: 11.1971 - val_accuracy: 0.5224\n",
      "Epoch 22/100\n",
      "184/184 [==============================] - 0s 667us/step - loss: 0.2661 - accuracy: 0.5276 - val_loss: 11.4819 - val_accuracy: 0.5265\n",
      "Epoch 23/100\n",
      "184/184 [==============================] - 0s 745us/step - loss: 0.2658 - accuracy: 0.5289 - val_loss: 11.2869 - val_accuracy: 0.5224\n",
      "Epoch 24/100\n",
      "184/184 [==============================] - 0s 680us/step - loss: 0.2657 - accuracy: 0.5218 - val_loss: 11.5240 - val_accuracy: 0.5286\n",
      "Epoch 25/100\n",
      "184/184 [==============================] - 0s 667us/step - loss: 0.2649 - accuracy: 0.5269 - val_loss: 11.1831 - val_accuracy: 0.5184\n",
      "Epoch 26/100\n",
      "184/184 [==============================] - 0s 741us/step - loss: 0.2648 - accuracy: 0.5283 - val_loss: 11.6035 - val_accuracy: 0.5224\n",
      "Epoch 27/100\n",
      "184/184 [==============================] - 0s 687us/step - loss: 0.2644 - accuracy: 0.5276 - val_loss: 11.7033 - val_accuracy: 0.5184\n",
      "Epoch 28/100\n",
      "184/184 [==============================] - 0s 674us/step - loss: 0.2647 - accuracy: 0.5228 - val_loss: 10.9321 - val_accuracy: 0.5255\n",
      "Epoch 29/100\n",
      "184/184 [==============================] - 0s 674us/step - loss: 0.2640 - accuracy: 0.5296 - val_loss: 11.7623 - val_accuracy: 0.5214\n",
      "Epoch 30/100\n",
      "184/184 [==============================] - 0s 663us/step - loss: 0.2640 - accuracy: 0.5293 - val_loss: 10.5212 - val_accuracy: 0.5265\n",
      "Epoch 31/100\n",
      "184/184 [==============================] - 0s 659us/step - loss: 0.2636 - accuracy: 0.5323 - val_loss: 12.1860 - val_accuracy: 0.5204\n",
      "Epoch 32/100\n",
      "184/184 [==============================] - 0s 645us/step - loss: 0.2637 - accuracy: 0.5317 - val_loss: 11.6465 - val_accuracy: 0.5163\n",
      "Epoch 33/100\n",
      "184/184 [==============================] - 0s 679us/step - loss: 0.2633 - accuracy: 0.5272 - val_loss: 11.3585 - val_accuracy: 0.5204\n",
      "Epoch 34/100\n",
      "184/184 [==============================] - 0s 901us/step - loss: 0.2629 - accuracy: 0.5296 - val_loss: 11.2886 - val_accuracy: 0.5143\n",
      "Epoch 35/100\n",
      "184/184 [==============================] - 0s 701us/step - loss: 0.2627 - accuracy: 0.5320 - val_loss: 11.8169 - val_accuracy: 0.5163\n",
      "Epoch 36/100\n",
      "184/184 [==============================] - 0s 711us/step - loss: 0.2628 - accuracy: 0.5300 - val_loss: 11.7911 - val_accuracy: 0.5194\n",
      "Epoch 37/100\n",
      "184/184 [==============================] - 0s 668us/step - loss: 0.2626 - accuracy: 0.5330 - val_loss: 11.4491 - val_accuracy: 0.5265\n",
      "Epoch 38/100\n",
      "184/184 [==============================] - 0s 646us/step - loss: 0.2625 - accuracy: 0.5354 - val_loss: 11.7268 - val_accuracy: 0.5276\n",
      "Epoch 39/100\n",
      "184/184 [==============================] - 0s 649us/step - loss: 0.2628 - accuracy: 0.5344 - val_loss: 11.7213 - val_accuracy: 0.5204\n",
      "Epoch 40/100\n",
      "184/184 [==============================] - 0s 687us/step - loss: 0.2619 - accuracy: 0.5374 - val_loss: 11.5894 - val_accuracy: 0.5286\n",
      "Epoch 41/100\n",
      "184/184 [==============================] - 0s 695us/step - loss: 0.2621 - accuracy: 0.5402 - val_loss: 11.6971 - val_accuracy: 0.5214\n",
      "Epoch 42/100\n",
      "184/184 [==============================] - 0s 683us/step - loss: 0.2616 - accuracy: 0.5436 - val_loss: 11.5522 - val_accuracy: 0.5153\n",
      "Epoch 43/100\n",
      "184/184 [==============================] - 0s 664us/step - loss: 0.2620 - accuracy: 0.5354 - val_loss: 11.7904 - val_accuracy: 0.5306\n",
      "Epoch 44/100\n",
      "184/184 [==============================] - 0s 718us/step - loss: 0.2619 - accuracy: 0.5364 - val_loss: 11.4836 - val_accuracy: 0.5347\n",
      "Epoch 45/100\n",
      "184/184 [==============================] - 0s 660us/step - loss: 0.2615 - accuracy: 0.5402 - val_loss: 11.7935 - val_accuracy: 0.5214\n",
      "Epoch 46/100\n",
      "184/184 [==============================] - 0s 658us/step - loss: 0.2614 - accuracy: 0.5398 - val_loss: 11.4253 - val_accuracy: 0.5153\n",
      "Epoch 47/100\n",
      "184/184 [==============================] - 0s 652us/step - loss: 0.2617 - accuracy: 0.5374 - val_loss: 11.7210 - val_accuracy: 0.5388\n",
      "Epoch 48/100\n",
      "184/184 [==============================] - 0s 656us/step - loss: 0.2616 - accuracy: 0.5429 - val_loss: 11.7690 - val_accuracy: 0.5235\n",
      "Epoch 49/100\n",
      "184/184 [==============================] - 0s 656us/step - loss: 0.2614 - accuracy: 0.5398 - val_loss: 12.6490 - val_accuracy: 0.5204\n",
      "Epoch 50/100\n",
      "184/184 [==============================] - 0s 744us/step - loss: 0.2614 - accuracy: 0.5361 - val_loss: 11.6911 - val_accuracy: 0.5265\n",
      "Epoch 51/100\n",
      "184/184 [==============================] - 0s 950us/step - loss: 0.2614 - accuracy: 0.5415 - val_loss: 11.8400 - val_accuracy: 0.5276\n",
      "Epoch 52/100\n",
      "184/184 [==============================] - 0s 869us/step - loss: 0.2615 - accuracy: 0.5354 - val_loss: 11.7670 - val_accuracy: 0.5214\n",
      "Epoch 53/100\n",
      "184/184 [==============================] - 0s 759us/step - loss: 0.2608 - accuracy: 0.5381 - val_loss: 11.2669 - val_accuracy: 0.5347\n",
      "Epoch 54/100\n",
      "184/184 [==============================] - 0s 819us/step - loss: 0.2614 - accuracy: 0.5381 - val_loss: 11.3841 - val_accuracy: 0.5408\n",
      "Epoch 55/100\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.5432 - val_loss: 12.4596 - val_accuracy: 0.5245\n",
      "Epoch 56/100\n",
      "184/184 [==============================] - 0s 722us/step - loss: 0.2605 - accuracy: 0.5425 - val_loss: 12.1294 - val_accuracy: 0.5265\n",
      "Epoch 57/100\n",
      "184/184 [==============================] - 0s 701us/step - loss: 0.2605 - accuracy: 0.5466 - val_loss: 11.9184 - val_accuracy: 0.5245\n",
      "Epoch 58/100\n",
      "184/184 [==============================] - 0s 691us/step - loss: 0.2605 - accuracy: 0.5442 - val_loss: 12.1271 - val_accuracy: 0.5235\n",
      "Epoch 59/100\n",
      "184/184 [==============================] - 0s 697us/step - loss: 0.2604 - accuracy: 0.5442 - val_loss: 12.1331 - val_accuracy: 0.5255\n",
      "Epoch 60/100\n",
      "184/184 [==============================] - 0s 716us/step - loss: 0.2602 - accuracy: 0.5405 - val_loss: 12.0989 - val_accuracy: 0.5235\n",
      "Epoch 61/100\n",
      "184/184 [==============================] - 0s 712us/step - loss: 0.2600 - accuracy: 0.5432 - val_loss: 12.3386 - val_accuracy: 0.5235\n",
      "Epoch 62/100\n",
      "184/184 [==============================] - 0s 723us/step - loss: 0.2604 - accuracy: 0.5412 - val_loss: 12.3486 - val_accuracy: 0.5265\n",
      "Epoch 63/100\n",
      "184/184 [==============================] - 0s 664us/step - loss: 0.2602 - accuracy: 0.5425 - val_loss: 11.9173 - val_accuracy: 0.5296\n",
      "Epoch 64/100\n",
      "184/184 [==============================] - 0s 720us/step - loss: 0.2603 - accuracy: 0.5402 - val_loss: 12.0618 - val_accuracy: 0.5265\n",
      "Epoch 65/100\n",
      "184/184 [==============================] - 0s 750us/step - loss: 0.2600 - accuracy: 0.5473 - val_loss: 12.7373 - val_accuracy: 0.5204\n",
      "Epoch 66/100\n",
      "184/184 [==============================] - 0s 741us/step - loss: 0.2609 - accuracy: 0.5398 - val_loss: 12.4756 - val_accuracy: 0.5245\n",
      "Epoch 67/100\n",
      "184/184 [==============================] - 0s 677us/step - loss: 0.2596 - accuracy: 0.5415 - val_loss: 12.2634 - val_accuracy: 0.5194\n",
      "Epoch 68/100\n",
      "184/184 [==============================] - 0s 709us/step - loss: 0.2600 - accuracy: 0.5398 - val_loss: 11.9649 - val_accuracy: 0.5173\n",
      "Epoch 69/100\n",
      "184/184 [==============================] - 0s 805us/step - loss: 0.2596 - accuracy: 0.5391 - val_loss: 11.9542 - val_accuracy: 0.5388\n",
      "Epoch 70/100\n",
      "184/184 [==============================] - 0s 753us/step - loss: 0.2602 - accuracy: 0.5429 - val_loss: 11.8843 - val_accuracy: 0.5276\n",
      "Epoch 71/100\n",
      "184/184 [==============================] - 0s 867us/step - loss: 0.2594 - accuracy: 0.5463 - val_loss: 12.4026 - val_accuracy: 0.5255\n",
      "Epoch 72/100\n",
      "184/184 [==============================] - 0s 877us/step - loss: 0.2594 - accuracy: 0.5507 - val_loss: 11.7104 - val_accuracy: 0.5276\n",
      "Epoch 73/100\n",
      "184/184 [==============================] - 0s 724us/step - loss: 0.2597 - accuracy: 0.5517 - val_loss: 12.2660 - val_accuracy: 0.5286\n",
      "Epoch 74/100\n",
      "184/184 [==============================] - 0s 769us/step - loss: 0.2597 - accuracy: 0.5422 - val_loss: 12.0792 - val_accuracy: 0.5276\n",
      "Epoch 75/100\n",
      "184/184 [==============================] - 0s 674us/step - loss: 0.2594 - accuracy: 0.5429 - val_loss: 12.4294 - val_accuracy: 0.5255\n",
      "Epoch 76/100\n",
      "184/184 [==============================] - 0s 710us/step - loss: 0.2591 - accuracy: 0.5466 - val_loss: 11.7165 - val_accuracy: 0.5357\n",
      "Epoch 77/100\n",
      "184/184 [==============================] - 0s 755us/step - loss: 0.2593 - accuracy: 0.5446 - val_loss: 12.3894 - val_accuracy: 0.5245\n",
      "Epoch 78/100\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.2591 - accuracy: 0.5477 - val_loss: 12.3127 - val_accuracy: 0.5224\n",
      "Epoch 79/100\n",
      "184/184 [==============================] - 0s 919us/step - loss: 0.2588 - accuracy: 0.5470 - val_loss: 12.5926 - val_accuracy: 0.5214\n",
      "Epoch 80/100\n",
      "184/184 [==============================] - 0s 873us/step - loss: 0.2592 - accuracy: 0.5432 - val_loss: 11.5560 - val_accuracy: 0.5235\n",
      "Epoch 81/100\n",
      "184/184 [==============================] - 0s 808us/step - loss: 0.2586 - accuracy: 0.5480 - val_loss: 12.3050 - val_accuracy: 0.5327\n",
      "Epoch 82/100\n",
      "184/184 [==============================] - 0s 720us/step - loss: 0.2593 - accuracy: 0.5398 - val_loss: 12.3222 - val_accuracy: 0.5276\n",
      "Epoch 83/100\n",
      "184/184 [==============================] - 0s 757us/step - loss: 0.2588 - accuracy: 0.5453 - val_loss: 12.4707 - val_accuracy: 0.5347\n",
      "Epoch 84/100\n",
      "184/184 [==============================] - 0s 750us/step - loss: 0.2583 - accuracy: 0.5477 - val_loss: 11.9985 - val_accuracy: 0.5255\n",
      "Epoch 85/100\n",
      "184/184 [==============================] - 0s 695us/step - loss: 0.2591 - accuracy: 0.5480 - val_loss: 12.2445 - val_accuracy: 0.5296\n",
      "Epoch 86/100\n",
      "184/184 [==============================] - 0s 801us/step - loss: 0.2581 - accuracy: 0.5483 - val_loss: 12.6627 - val_accuracy: 0.5327\n",
      "Epoch 87/100\n",
      "184/184 [==============================] - 0s 669us/step - loss: 0.2587 - accuracy: 0.5453 - val_loss: 12.3427 - val_accuracy: 0.5255\n",
      "Epoch 88/100\n",
      "184/184 [==============================] - 0s 728us/step - loss: 0.2587 - accuracy: 0.5402 - val_loss: 12.0466 - val_accuracy: 0.5327\n",
      "Epoch 89/100\n",
      "184/184 [==============================] - 0s 699us/step - loss: 0.2583 - accuracy: 0.5439 - val_loss: 12.4143 - val_accuracy: 0.5337\n",
      "Epoch 90/100\n",
      "184/184 [==============================] - 0s 741us/step - loss: 0.2584 - accuracy: 0.5446 - val_loss: 11.9657 - val_accuracy: 0.5347\n",
      "Epoch 91/100\n",
      "184/184 [==============================] - 0s 884us/step - loss: 0.2583 - accuracy: 0.5511 - val_loss: 12.6715 - val_accuracy: 0.5235\n",
      "Epoch 92/100\n",
      "184/184 [==============================] - 0s 927us/step - loss: 0.2585 - accuracy: 0.5449 - val_loss: 11.6965 - val_accuracy: 0.5286\n",
      "Epoch 93/100\n",
      "184/184 [==============================] - 0s 790us/step - loss: 0.2581 - accuracy: 0.5456 - val_loss: 12.3811 - val_accuracy: 0.5357\n",
      "Epoch 94/100\n",
      "184/184 [==============================] - 0s 779us/step - loss: 0.2581 - accuracy: 0.5456 - val_loss: 12.4909 - val_accuracy: 0.5327\n",
      "Epoch 95/100\n",
      "184/184 [==============================] - 0s 816us/step - loss: 0.2581 - accuracy: 0.5466 - val_loss: 12.2881 - val_accuracy: 0.5378\n",
      "Epoch 96/100\n",
      "184/184 [==============================] - 0s 872us/step - loss: 0.2579 - accuracy: 0.5439 - val_loss: 12.3459 - val_accuracy: 0.5306\n",
      "Epoch 97/100\n",
      "184/184 [==============================] - 0s 755us/step - loss: 0.2580 - accuracy: 0.5453 - val_loss: 12.0007 - val_accuracy: 0.5378\n",
      "Epoch 98/100\n",
      "184/184 [==============================] - 0s 676us/step - loss: 0.2582 - accuracy: 0.5463 - val_loss: 12.5349 - val_accuracy: 0.5276\n",
      "Epoch 99/100\n",
      "184/184 [==============================] - 0s 655us/step - loss: 0.2576 - accuracy: 0.5521 - val_loss: 12.1892 - val_accuracy: 0.5367\n",
      "Epoch 100/100\n",
      "184/184 [==============================] - 0s 714us/step - loss: 0.2577 - accuracy: 0.5507 - val_loss: 12.7149 - val_accuracy: 0.5306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a3ef58b0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(6, input_dim=11, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')])\n",
    "net2.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "net2.fit(X_train, y_train, epochs=100, batch_size = 16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f4d339c2-0258-4c71-ba4d-aa2c1f7f2808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 641us/step - loss: 0.2613 - accuracy: 0.5439\n",
      "Test results - Loss: 0.26134181022644043 - Accuracy: 0.5438775420188904%\n",
      "31/31 [==============================] - 0s 366us/step\n",
      "(980,)\n",
      "(980, 7)\n",
      "[[3. 4. 3. ... 3. 3. 3.]\n",
      " [3. 3. 3. ... 4. 3. 3.]\n",
      " [3. 3. 3. ... 3. 3. 3.]\n",
      " ...\n",
      " [3. 3. 4. ... 3. 3. 3.]\n",
      " [3. 3. 3. ... 3. 3. 3.]\n",
      " [3. 3. 3. ... 3. 3. 3.]]\n",
      "tf.Tensor(\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [  0   0   1   7   4   0   0]\n",
      " [  1  10  75 133  46  12   1]\n",
      " [  1  16 172 244 108  27   0]\n",
      " [  1   5  40  58  14   2   2]\n",
      " [  0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0]], shape=(7, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Test the model after training\n",
    "test_results = net2.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "y_pred = np.argmax(net.predict(X_test), axis=-1)\n",
    "print(y_pred.shape)\n",
    "print(y_val.shape)\n",
    "print(y_val)\n",
    "\n",
    "b = (np.argmax(y_val, axis = 1) + 3)\n",
    "\n",
    "print(tf.math.confusion_matrix(y_pred, b)[:-3,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8122c0-1946-4e0c-9255-259f47db3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vanishing gradients: Yes in net 2, too many layers possibly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
